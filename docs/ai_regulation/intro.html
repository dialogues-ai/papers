<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-ai_regulation/intro">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.0">
<title data-rh="true">General Statement | dialogues.ai</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://dialogues-ai.github.io/papers/docs/ai_regulation/intro"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="General Statement | dialogues.ai"><meta data-rh="true" name="description" content="*Relate AI behavior to human behavior,"><meta data-rh="true" property="og:description" content="*Relate AI behavior to human behavior,"><link data-rh="true" rel="icon" href="/papers/img/DI+logo.png"><link data-rh="true" rel="canonical" href="https://dialogues-ai.github.io/papers/docs/ai_regulation/intro"><link data-rh="true" rel="alternate" href="https://dialogues-ai.github.io/papers/docs/ai_regulation/intro" hreflang="en"><link data-rh="true" rel="alternate" href="https://dialogues-ai.github.io/papers/docs/ai_regulation/intro" hreflang="x-default"><link rel="stylesheet" href="/papers/assets/css/styles.a813940b.css">
<link rel="preload" href="/papers/assets/js/runtime~main.c2d1fb80.js" as="script">
<link rel="preload" href="/papers/assets/js/main.28e4dbe5.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(e){}return e}()||function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,e("light"))}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/papers/"><div class="navbar__logo"><img src="/papers/img/dialogues_logo.png" alt="Dialogues" class="themedImage_ToTc themedImage--light_HNdA"><img src="/papers/img/dialogues_logo_dark.png" alt="Dialogues" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate"></b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/papers/docs/ai_regulation/gamemaking">Papers</a></div><div class="navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex="-1" class="sidebarLogo_isFc" href="/papers/"><img src="/papers/img/dialogues_logo.png" alt="Dialogues" class="themedImage_ToTc themedImage--light_HNdA"><img src="/papers/img/dialogues_logo_dark.png" alt="Dialogues" class="themedImage_ToTc themedImage--dark_i4oU"><b></b></a><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/papers/docs/ai_regulation/intro">AI Regulation</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/papers/docs/ai_regulation/intro">General Statement</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/papers/docs/ai_regulation/ignorance_wall">The Ignorance Wall</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/papers/docs/ai_regulation/gamemaking">Game-Making</a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/papers/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">AI Regulation</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">General Statement</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>General Statement</h1><p><strong><em>Relate AI behavior to human behavior,<br>and pick the better angels of our nature.</em></strong></p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="ai-regulation-a-human-perspective">AI Regulation: A Human Perspective<a href="#ai-regulation-a-human-perspective" class="hash-link" aria-label="Direct link to AI Regulation: A Human Perspective" title="Direct link to AI Regulation: A Human Perspective">​</a></h2><p>AI needs regulation. The regulation I am talking about is the kind of regulation when a wisdom gets passed from an older generation to a younger generation—like how a dad might tell his kid to look both ways before crossing the street. In this case, it is from those working in the industry, speaking both to newcomers to the field and to those who look at it from the outside. Likely, it is going to be the majority, those who do not understand AI or machine learning, who make the voting calls to limit its development. It is better these votes are made from an informed public.</p><p>No doubt, AI can be smarter than a human. An AI can hold all the information there is on Wikipedia. But, if a human had all that information, so what? What is it to us but someone you might want on your trivia team? An AI can beat all chess players, too. And, again, so what is that to us? It can’t sandbag the tournaments and beat everyone. No, it is no longer allowed as a participant. There is more to the value of information than having the ability to recite it upon command.</p><p>AI is a powerful tool that makes decisions of its own, and, in the arenas those choices are carried out, it has significant impacts on people. AI is in need of regulation in order for it and for people to continue moving forward in a game which includes humans and everyone wants to continue to play. It needs to have its own rules for how it plays the game.</p><p>AI is a new piece invented on life’s chess board, and its new abilities need careful consideration for how they will play with others. Like a child playing chess, it cannot swing its arm across the board, knock down all the pieces and say it wins, nor can it show up like superman and have one weakness that doesn’t even exist in the game.</p><p>AI can be nerfed now, but it needs to be nerfed with consideration. AI is not to be made to equal the tools of everything else. It is a superior tool, and its superior position should be allowed. For instance, you don’t want to limit the use of electricity and try to keep fire in the game as well. So, when we define its position, we should focus our efforts on how AI relates to people.</p><p>Regulation in this paper is defined as a way to set the parameters around how AI is to behave amongst people so all human players can continue to exist. People’s roles are allowed to change, but the AI cannot suddenly opt to be a weapon and knock mankind off the planet. While wiping mankind from the planet is a digestible idea, and the threat has some truth, its real threats and the steps to prevent them from causing damage needs to be far more thoughtful. If you were to ascribe to Kahneman’s thinking-fast-and-slow duality, then I would hope more time is spent thinking slow when considering what is before us.</p><p>The aim of creating regulations around AI is to create a game people wish to continue to play. It involves creating testing environments to simulate its effects. It involves placing limits to the domain one AI makes decisions around, like how accountants separate the responsibilities where one is responsible for moving the money and one is responsible for counting the money. Where AI has elevated itself to its own game, competition among AIs is good. It can compete for roles. There is not one AI to rule them all. There exists a society of independent AI’s that have responsibilities for a very specific domain.</p><p>Now is the time for all of this to be considered. The last thing that is needed is for a Congress to act out, again, in a post-Twin Tower fury after an AI disaster happens, and be pressured by an enraged public to act quick and make laws, then, in regards to something they know little about. Those kinds of decisions rarely bode well. If we start now, maybe the disaster can be avoided, and there is time to make good considerations.</p><p>I am one guy who can do this. I will add a voice. In my voice, I will approach this not from an entirely technical point of view, but, rather, from that of a gamesman. I want to take a look at the kind of people we are. I don&#x27;t want to talk about all the good intentions and the do-gooders. I want to point out the follies we make—the wall that is ignorance. The charades that are played in order to find a place of greater power and comfort. The willful abandonment of a reality in pursuit to live a dream. And, finally, the willingness to surrender one&#x27;s freedoms to let a greater authority make decisions for oneself, something the COVID pandemic has kindly offered as a popular and understood example.</p><p>AI models try to best fit the data they represent, which, when mapped on the data of human behaviors, enables AI to be a mirror of humanity—their choices, actions, and creations. I will show that those behaviors people are afraid of an AI possessing, such as denying another their existence and right to live, are ones humanity has not yet rid itself of yet. </p><p>AI can be a great tool, but the reflection in the mirror has the potential to be one people are not prepared to face. Personally, of all the mirrors offered to gaze into, this seems the most fruitful—no matter what it looks like. It creates an opportunity to learn. It reveals who we are in terms of the kinds of choices we make, and the patterns in our behaviors. Unlike the mirrors found in bathrooms, bedrooms, hallways, or gyms, this mirror of behavior is not vain.</p><p>In a lot of cases, we don’t want to build AIs that are perfect mirrors, but rather, improved mirrors—ideal mirrors—that behave, not in the way we actually behave, but in the way we wish to behave. They can be the teachers and the coaches that nudge us in the direction we wish to head. When the playing of games are reinvestments into the way things are, we wish to create higher-level games that advance the way things are. It is possible to use these mirrors to influence our behaviors towards a better place. But, to create such a mirror, requires us to spend time articulating what we are, flaws and all, and what we aspire to be.</p><p>I will address two major things in this paper:</p><ol><li>Errors by nature in human behaviors</li><li>How ML models create games</li></ol><p>Rules are stated to address the particular problem along the way. All rules will be printed in order at the end of the paper.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/dialogues-ai/papers/tree/main/docs/ai_regulation/intro.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--next" href="/papers/docs/ai_regulation/ignorance_wall"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">The Ignorance Wall</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#ai-regulation-a-human-perspective" class="table-of-contents__link toc-highlight">AI Regulation: A Human Perspective</a></li></ul></div></div></div></div></main></div></div></div>
<script src="/papers/assets/js/runtime~main.c2d1fb80.js"></script>
<script src="/papers/assets/js/main.28e4dbe5.js"></script>
</body>
</html>